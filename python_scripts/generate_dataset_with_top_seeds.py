#!/usr/bin/env python3
"""
Script to generate a dataset using the top-performing seeds identified by get_top_seeds.py.
This script loads the top seeds, applies them to generate images with specific object counts,
and saves the resulting dataset both locally and to HuggingFace Hub.
"""

import torch
import numpy as np
from PIL import Image
import pickle
import argparse
import os
import random
from tqdm import tqdm
from datasets import Dataset
import sys

from diffusers import StableDiffusionPipeline
from diffusers import UNet2DConditionModel


def load_objects_from_file(file_path):
    """Load object prompts from a file in the prompt_dataset folder."""
    objects = []
    with open(file_path, 'r') as f:
        for line in f:
            line = line.strip()
            if line:
                parts = line.split(", ")
                if len(parts) >= 3:
                    index, single, plural = parts
                    # Store both singular and plural forms
                    objects.append((single, plural))
    return objects


def load_settings_from_file(file_path):
    """Load settings/backgrounds from a file in the prompt_dataset folder."""
    settings = []
    with open(file_path, 'r') as f:
        for line in f:
            line = line.strip()
            if line:
                settings.append(line)
    return settings


def load_top_seeds(seeds_file):
    """Load top seeds from the pickle file generated by get_top_seeds.py."""
    try:
        with open(seeds_file, 'rb') as f:
            seeds_dict = pickle.load(f)
        
        # Handle both formats (with or without --include_stats)
        processed_seeds = {}
        for count, value in seeds_dict.items():
            if isinstance(value, dict) and "seeds" in value:
                # Format with --include_stats
                processed_seeds[count] = value["seeds"]
            else:
                # Simple format
                processed_seeds[count] = value
                
        return processed_seeds
    except Exception as e:
        raise ValueError(f"Error loading seeds file: {e}")


def main():
    parser = argparse.ArgumentParser(description="Generate a dataset using top-performing seeds")

    parser.add_argument(
        "--pipeline", 
        type=str, 
        default="stabilityai/stable-diffusion-2-1",
        help="Diffusion model pipeline to use (default: stabilityai/stable-diffusion-2-1)"
    )

    parser.add_argument("--model_params", type=str,
                        default="stable-diffusion-2-1_obj15_set4_seed100",
                        help="Model parameters string (e.g., stable-diffusion-2-1_obj15_set4_seed100)")
    
    parser.add_argument("--objects_file", type=str, 
                        default="prompt_dataset/objects_train.txt",
                        help="Path to file containing object prompts")
    
    parser.add_argument("--settings_file", type=str, 
                        default="prompt_dataset/backgrounds_train.txt",
                        help="Path to file containing settings/backgrounds")
    
    parser.add_argument("--base_dir", type=str, default="output",
                        help="Base directory containing all data")
    
    parser.add_argument("--seed", type=int, default=77,
                        help="Random seed for reproducibility")
                
    parser.add_argument("--device", type=str, default="cuda",
                        help="Device to use for generation (cuda, cpu)")
    
    parser.add_argument("--push_to_hub", action="store_true",
                        help="Push the dataset to HuggingFace Hub")
    
    parser.add_argument("--dataset_name", type=str, default="HF_USERNAME/stable-diffusion-2-1_obj15_set4_seed100",
                        help="Name of the dataset on HuggingFace Hub (required if --push_to_hub is set)")
    
    args = parser.parse_args()
    
    # Validate arguments
    if args.push_to_hub and not args.dataset_name:
        raise ValueError("--dataset_name is required when --push_to_hub is set")
    
    # Set random seed for reproducibility
    random.seed(args.seed)
    
    # Setup paths
    model_dir = os.path.join(args.base_dir, args.model_params)
    seeds_file = os.path.join(model_dir, "seed-analysis", "top_seeds.pkl")
    output_dir = os.path.join(model_dir, "dataset")
    
    # Ensure output directory exists
    os.makedirs(output_dir, exist_ok=True)
    
    # Dictionary mapping numbers to words
    nb_to_word = {2: "two", 3: "three", 4: "four", 5: "five", 6: "six"}
    
    # Load objects, settings, and top seeds
    print(f"Loading objects from {args.objects_file}")
    objects = load_objects_from_file(args.objects_file)
    
    print(f"Loading settings from {args.settings_file}")
    settings = load_settings_from_file(args.settings_file)
    
    print(f"Loading top seeds from {seeds_file}")
    seeds_by_count = load_top_seeds(seeds_file)
    
    # Initialize the Stable Diffusion pipeline
    print("Initializing Stable Diffusion pipeline...")
    pipe = StableDiffusionPipeline.from_pretrained(
        args.pipeline, 
        torch_dtype=torch.float16
    )
    pipe.to(args.device)
    pipe.safety_checker = lambda images, **kwargs: (images, [False] * len(images))
    
    # Dataset dictionary
    ds_dict = {"image": [], "prompt": [], "count": [], "seed": [], "image_path": []}
    
    # Generate images
    gen_count = 0
    print(f"Generating images and saving to {output_dir}...")
    
    for obj_idx, obj in enumerate(tqdm(objects, desc="Processing objects")):
        for count in [2, 3, 4, 5, 6]:
            for idx_sett, setting in enumerate(settings):
                # Use plural form for the prompt
                single, plural = obj
                prompt = f"{nb_to_word[count]} {plural}, {setting}"
                
                # Select a random seed from the top seeds for this count
                if count in seeds_by_count and seeds_by_count[count]:
                    seed = int(random.choice(seeds_by_count[count]))
                else:
                    print(f"Warning: No top seeds found for count {count}, using gen_count {gen_count}")
                    seed = gen_count
                
                print(f"Generating: {prompt} (Seed: {seed})")
                
                # Generate the image
                image = pipe(
                    prompt,
                    generator=torch.Generator(device=args.device).manual_seed(seed)
                ).images[0]
                
                # Save individual image
                image_filename = f"{gen_count:04d}_{count}_{obj_idx:02d}_{idx_sett:02d}.png"
                image_path = os.path.join(output_dir, image_filename)
                image.save(image_path)
                
                # Save to dataset dictionary
                ds_dict['prompt'].append(prompt)
                ds_dict['image'].append(image)
                ds_dict['count'].append(count)
                ds_dict['seed'].append(seed)
                ds_dict['image_path'].append(image_path)
                
                gen_count += 1
    
    # Save dataset metadata
    meta_file = os.path.join(output_dir, "metadata.pkl")
    with open(meta_file, 'wb') as f:
        # Don't save the actual images in the pickle file, just their paths
        meta_dict = {
            "prompt": ds_dict["prompt"],
            "count": ds_dict["count"],
            "seed": ds_dict["seed"],
            "image_path": ds_dict["image_path"]
        }
        pickle.dump(meta_dict, f)
    
    print(f"Dataset generation complete! Generated {gen_count} images.")
    print(f"Metadata saved to {meta_file}")
    
    # Create HuggingFace dataset and push to hub if requested
    if args.push_to_hub:
        print(f"Creating HuggingFace Dataset and pushing to {args.dataset_name}...")
        
        try:
            # Prepare dataset dict for HuggingFace
            # We need to convert PIL images to bytes for the Dataset
            hf_dict = {
                "prompt": ds_dict["prompt"],
                "count": ds_dict["count"],
                "seed": ds_dict["seed"]
            }
            
            # For HuggingFace, we convert the PIL images to numpy arrays
            print("Converting images for HuggingFace format...")
            # hf_dict["image"] = [np.array(img) for img in ds_dict["image"]]
            hf_dict["image"] = [img for img in ds_dict["image"]]
            
            # Create the dataset
            print("Creating dataset...")
            ds = Dataset.from_dict(
                hf_dict
            )
            
            # Push to HuggingFace Hub using cached credentials
            print(f"Pushing dataset to HuggingFace Hub at {args.dataset_name}...")
            ds.push_to_hub(
                args.dataset_name,
                private=False
            )
            
            print(f"Dataset successfully pushed to HuggingFace Hub: {args.dataset_name}")
            print(f"Local dataset saved at: {output_dir}")
            
        except ImportError:
            print("Error: 'datasets' package is required for HuggingFace integration.")
            print("Install it with: pip install datasets")
            sys.exit(1)
        except OverflowError as e:
            print(f"Error: {e}")
            print("Try reducing the number of images or splitting into multiple datasets.")
            sys.exit(1)
        except Exception as e:
            print(f"Error pushing to HuggingFace Hub: {e}")
            print("Please ensure you have valid cached credentials.")
            print("Run 'huggingface-cli login' to log in if necessary.")
            sys.exit(1)
    else:
        print(f"Local dataset saved at: {output_dir}")


if __name__ == "__main__":
    import sys  # Import sys for exit codes
    main()
