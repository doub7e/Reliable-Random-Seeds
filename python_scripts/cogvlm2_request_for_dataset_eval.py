"""
This script is designed to use CogVLM2 to analyze images generated with reliable seeds.
It loads images from a dataset directory, queries CogVLM2 about the number of objects in each image,
and saves the responses for further analysis.
"""
import requests
import json
import base64
import os
import pickle
import argparse
from tqdm import tqdm
import re

base_url = "http://127.0.0.1:8000"


def create_chat_completion(model, messages, temperature=0.8, max_tokens=2048, top_p=0.8, use_stream=False):
    """
    This function sends a request to the chat API to generate a response based on the given messages.

    Args:
        model (str): The name of the model to use for generating the response.
        messages (list): A list of message dictionaries representing the conversation history.
        temperature (float): Controls randomness in response generation. Higher values lead to more random responses.
        max_tokens (int): The maximum length of the generated response.
        top_p (float): Controls diversity of response by filtering less likely options.
        use_stream (bool): Determines whether to use a streaming response or a single response.

    The function constructs a JSON payload with the specified parameters and sends a POST request to the API.
    It then handles the response, either as a stream (for ongoing responses) or a single message.
    """

    data = {
        "model": model,
        "messages": messages,
        "stream": use_stream,
        "max_tokens": max_tokens,
        "temperature": temperature,
        "top_p": top_p,
    }

    response = requests.post(f"{base_url}/v1/chat/completions", json=data, stream=use_stream)
    if response.status_code == 200:
        if use_stream:
            # Process streaming response
            for line in response.iter_lines():
                if line:
                    decoded_line = line.decode('utf-8')[6:]
                    try:
                        response_json = json.loads(decoded_line)
                        content = response_json.get("choices", [{}])[0].get("delta", {}).get("content", "")
                        print(content, end="", flush=True)
                    except:
                        print("Special Token:", decoded_line)
        else:
            # Process non-streaming response
            decoded_line = response.json()
            content = decoded_line.get("choices", [{}])[0].get("message", "").get("content", "")
            return content
    else:
        print("Error:", response.status_code)
        return None


def encode_image(image_path):
    """
    Encodes an image file into a base64 string.
    Args:
        image_path (str): The path to the image file.

    This function opens the specified image file, reads its content, and encodes it into a base64 string.
    The base64 encoding is used to send images over HTTP as text.
    """
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


def simple_image_chat(objects=None, count=None, use_stream=False, img_path=None):
    """
    Facilitates a simple chat interaction involving an image.

    Args:
        objects (str): The type of objects in the image to ask about
        count (int): The expected count of objects
        use_stream (bool): Specifies whether to use streaming for chat responses
        img_path (str): Path to the image file to be included in the chat

    This function encodes the specified image and constructs a predefined conversation involving the image.
    It then calls `create_chat_completion` to generate a response from the model.
    """
    img_url = f"data:image/jpeg;base64,{encode_image(img_path)}"
    messages = [
        {
            "role": "user",
            "content": [
                {
                    "type": "text", "text": f"Answer in one sentence: How many {objects} are in this image?",
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": img_url
                    },
                },
            ],
        },
    ]
    
    resp = create_chat_completion("cogvlm2", messages=messages, use_stream=use_stream)
    return resp


def load_metadata(metadata_file):
    """
    Load the metadata from the pickle file generated by generate_dataset_with_top_seeds.py.
    
    Args:
        metadata_file (str): Path to the metadata pickle file
        
    Returns:
        dict: The metadata dictionary containing prompts, counts, seeds, and image paths
    """
    try:
        with open(metadata_file, 'rb') as f:
            metadata = pickle.load(f)
        return metadata
    except Exception as e:
        raise ValueError(f"Error loading metadata file: {e}")


def main():
    parser = argparse.ArgumentParser(description="Analyze dataset images with CogVLM2")
    parser.add_argument("--model_params", type=str, default="stable-diffusion-2-1_obj15_set4_seed100",
                        help="Model parameters (e.g., 'stable-diffusion-2-1_obj15_set4_seed100')")
    
    parser.add_argument("--base_dir", type=str, default="output",
                        help="Base directory containing all data")
    
    parser.add_argument("--output_subdir", type=str, default="dataset_evaluation",
                        help="Subdirectory name to save the evaluation results in")
    
    args = parser.parse_args()
    
    # Set up directories based on the model parameters
    model_dir = os.path.join(args.base_dir, args.model_params)
    dataset_dir = os.path.join(model_dir, "dataset")
    metadata_file = os.path.join(dataset_dir, "metadata.pkl")
    output_dir = os.path.join(model_dir, args.output_subdir)
    
    # Ensure the dataset directory exists
    if not os.path.exists(dataset_dir):
        print(f"Error: Dataset directory '{dataset_dir}' does not exist.")
        print("Please run generate_dataset_with_top_seeds.py first or specify the correct directory.")
        exit(1)
    
    # Ensure the output directory exists
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"Created output directory: {output_dir}")
    
    # Load metadata
    print(f"Loading metadata from {metadata_file}")
    metadata = load_metadata(metadata_file)
    
    # Extract prompts, counts, and file paths
    prompts = metadata["prompt"]
    counts = metadata["count"]
    image_paths = metadata["image_path"]
    seeds = metadata["seed"]
    
    # Organize data by count
    count_data = {}
    for i in range(len(prompts)):
        count = counts[i]
        if count not in count_data:
            count_data[count] = []
        
        # Extract object name from prompt using regex
        # Pattern matches "two X," or "three Y," etc.
        match = re.search(r'(\w+)\s+(\w+),', prompts[i])
        if match:
            object_name = match.group(2)
            
            # Add this item to the count data
            count_data[count].append({
                "prompt": prompts[i],
                "image_path": image_paths[i],
                "object": object_name,
                "seed": seeds[i]
            })
    
    # Process each count
    for count, items in count_data.items():
        print(f"\nProcessing {len(items)} images for count {count}")
        results = {}
        
        # Process each image
        for item in tqdm(items, desc=f"Count {count}"):
            image_path = item["image_path"]
            object_name = item["object"]
            seed = item["seed"]
            
            try:
                # Create a unique key using seed and object
                key = (str(seed), object_name)
                
                # Initialize the list for this key if it doesn't exist
                if key not in results:
                    results[key] = []
                
                # Query the model
                resp = simple_image_chat(objects=object_name, count=count, use_stream=False, img_path=image_path)
                
                if resp:
                    results[key].append(resp)
                    print(f"Image: {os.path.basename(image_path)}, Response: {resp}")
                else:
                    print(f"Warning: No response for {image_path}")
                    results[key].append(None)
            except Exception as e:
                print(f"Error processing {image_path}: {e}")
                if key in results:
                    results[key].append(f"ERROR: {str(e)}")
        
        # Save results for this count
        output_file = os.path.join(output_dir, f"responses_count{count}.pkl")
        with open(output_file, 'wb') as f:
            pickle.dump(results, f)
        print(f"Saved results for count {count} to {output_file}")
    
    print("\Complete! The results can be used with evaluate_and_rectify_dataset.py for analysis.")


if __name__ == "__main__":
    main() 
