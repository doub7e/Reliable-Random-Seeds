#!/usr/bin/env python3
"""
Script to generate images for final evaluation of fine-tuned models.
This script loads evaluation objects and backgrounds, generates images with different
counts of objects, and saves them for assessment with GPT-4o.

The workflow typically follows these steps:
1. Generate evaluation images with this script
2. Evaluate the images with gpt4o_request_evaluation.py
3. Analyze the results with final_evaluation.py

Example usage:
    # Generate evaluation images with default model and parameters
    python python_scripts/generate_images_for_evaluation.py
    
    # Generate evaluation images for a pretrained model
    python python_scripts/generate_images_for_evaluation.py --model_name "stable-diffusion-2-1" --output_dir "eval/pretrained" --unet_path ""
    
    # Generate evaluation images for a fine-tuned model with a custom UNet path
    python python_scripts/generate_images_for_evaluation.py --model_name "fine-tuned-model" --unet_path "/path/to/custom/unet" --output_dir "eval/fine-tuned"
"""

import argparse
import torch
import os
import random
import pickle
from tqdm import tqdm
from diffusers import StableDiffusionPipeline, UNet2DConditionModel


def load_objects_from_file(file_path):
    """Load object prompts from a file in the prompt_dataset folder."""
    objects = []
    with open(file_path, 'r') as f:
        for line in f:
            line = line.strip()
            if line:
                parts = line.split(", ")
                if len(parts) >= 3:
                    index, single, plural = parts
                    # Store both singular and plural forms
                    objects.append((single, plural))
    return objects


def load_settings_from_file(file_path):
    """Load settings/backgrounds from a file in the prompt_dataset folder."""
    settings = []
    with open(file_path, 'r') as f:
        for line in f:
            line = line.strip()
            if line:
                settings.append(line)
    return settings


def load_top_seeds(seeds_file):
    """Load top seeds from the pickle file generated by get_top_seeds.py."""
    try:
        with open(seeds_file, 'rb') as f:
            seeds_dict = pickle.load(f)
        
        # Handle both formats (with or without --include_stats)
        processed_seeds = {}
        for count, value in seeds_dict.items():
            if isinstance(value, dict) and "seeds" in value:
                # Format with --include_stats
                processed_seeds[count] = value["seeds"]
            else:
                # Simple format
                processed_seeds[count] = value
                
        return processed_seeds
    except Exception as e:
        print(f"Warning: Error loading seeds file: {e}")
        return None


def parse_arguments():
    """Parse command line arguments."""
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    
    parser = argparse.ArgumentParser(description="Generate images for fine-tuned model evaluation")
    
    parser.add_argument(
        "--pipeline", 
        type=str, 
        default="stabilityai/stable-diffusion-2-1",
        help="Diffusion model pipeline to use (default: stabilityai/stable-diffusion-2-1)"
    )
    
    parser.add_argument(
        "--unet_path", 
        type=str, 
        default="output/stable-diffusion-2-1_obj15_set4_seed100/finetuned_models/d1d2mu1u2-attn1+attn2-qk-true/checkpoint-5000/unet/",
        help="Path to a fine-tuned UNet model (default: output/stable-diffusion-2-1_obj15_set4_seed100/finetuned_models/d1d2mu1u2-attn1+attn2-qk-true/checkpoint-5000/unet/)"
    )
    
    parser.add_argument(
        "--model_name", 
        type=str, 
        default="stable-diffusion-2-1_obj15_set4_seed100",
        help="Name of the model for output directory naming (default: stable-diffusion-2-1_obj15_set4_seed100)"
    )
    
    parser.add_argument(
        "--objects_file", 
        type=str, 
        default=os.path.join(base_dir, "prompt_dataset", "objects_eval.txt"),
        help="Path to file containing object prompts"
    )
    
    parser.add_argument(
        "--settings_file", 
        type=str, 
        default=os.path.join(base_dir, "prompt_dataset", "backgrounds_eval.txt"),
        help="Path to file containing settings/backgrounds"
    )
    
    parser.add_argument(
        "--output_dir", 
        type=str, 
        default=None,
        help="Directory to save the generated images (default: output/{model_name}/generated-images-for-evaluation/)"
    )
    
    parser.add_argument(
        "--use_top_seeds", 
        action="store_true",
        help="Use top seeds from seed-mining for image generation"
    )
    
    parser.add_argument(
        "--top_seeds_file", 
        type=str, 
        default=None,
        help="Path to the top seeds pickle file (default: output/{model_name}/seed-analysis/top_seeds.pkl)"
    )
    
    parser.add_argument(
        "--num_images", 
        type=int, 
        default=1,
        help="Number of images to generate per object and count combination"
    )
    
    parser.add_argument(
        "--num_objects", 
        type=int, 
        default=None,
        help="Number of objects to use from the objects file (default: all)"
    )
    
    parser.add_argument(
        "--num_settings", 
        type=int, 
        default=None,
        help="Number of settings to use from the settings file (default: all)"
    )
    
    parser.add_argument(
        "--seed", 
        type=int, 
        default=77,
        help="Random seed for reproducibility"
    )
    
    parser.add_argument(
        "--device", 
        type=str, 
        default="cuda",
        help="Device to use for generation (cuda, cpu)"
    )
    
    args = parser.parse_args()
    
    # Set default output directory if not provided
    if args.output_dir is None:
        args.output_dir = f"output/{args.model_name}/generated-images-for-evaluation/"
    
    return args


def main():
    # Parse command line arguments
    args = parse_arguments()
    
    # Set random seed for reproducibility
    random.seed(args.seed)
    torch.manual_seed(args.seed)
    
    # Ensure output directory exists
    os.makedirs(args.output_dir, exist_ok=True)
    
    # Dictionary mapping numbers to words
    nb_to_word = {2: "two", 3: "three", 4: "four", 5: "five", 6: "six"}
    
    # Load objects and settings
    print(f"Loading objects from {args.objects_file}")
    objects = load_objects_from_file(args.objects_file)
    if args.num_objects:
        objects = objects[:args.num_objects]
        print(f"Using first {args.num_objects} objects")
    
    print(f"Loading settings from {args.settings_file}")
    settings = load_settings_from_file(args.settings_file)
    if args.num_settings:
        settings = settings[:args.num_settings]
        print(f"Using first {args.num_settings} settings")
    
    # Load top seeds if using them
    seeds_by_count = None
    if args.use_top_seeds:
        seeds_file = args.top_seeds_file
        if not seeds_file:
            seeds_file = os.path.join("output", args.model_name, "seed-analysis", "top_seeds.pkl")
        
        print(f"Loading top seeds from {seeds_file}")
        seeds_by_count = load_top_seeds(seeds_file)
        if seeds_by_count:
            print(f"Successfully loaded top seeds for counts: {', '.join(map(str, seeds_by_count.keys()))}")
        else:
            print("Falling back to random seeds")
            args.use_top_seeds = False
    
    # Initialize the Stable Diffusion pipeline
    print("Initializing Stable Diffusion pipeline...")
    
    if args.unet_path and args.unet_path != "":
        print(f"Loading custom UNet from {args.unet_path}")
        unet = UNet2DConditionModel.from_pretrained(args.unet_path, torch_dtype=torch.float16)
        pipe = StableDiffusionPipeline.from_pretrained(args.pipeline, unet=unet, torch_dtype=torch.float16)
    else:
        pipe = StableDiffusionPipeline.from_pretrained(args.pipeline, torch_dtype=torch.float16)
    
    pipe.to(args.device)
    pipe.safety_checker = lambda images, **kwargs: (images, [False] * len(images))
    
    # Track generated images and metadata
    gen_count = 0
    metadata = {
        "prompts": [],
        "objects": [],
        "counts": [],
        "seeds": [],
        "settings": [],
        "filenames": []
    }
    
    # Calculate total images to generate for progress bar
    total_images = len(objects) * len(settings) * 5 * args.num_images  # 5 counts (2-6) per object-setting combination
    
    # Generate images
    print(f"Generating {total_images} evaluation images and saving to {args.output_dir}...")
    
    with tqdm(total=total_images, desc="Generating images") as pbar:
        for setting in settings:
            for obj in objects:
                for count in range(2, 7):  # Generate for counts 2-6
                    # Use singular form for count=1, plural form for count>1
                    single, plural = obj
                    
                    # Create base prompt and full prompt with setting
                    base_prompt = f"{nb_to_word[count]} {plural}"
                    prompt = base_prompt + ", " + setting
                    
                    for img_idx in range(args.num_images):
                        # Select seed - either from top seeds or use gen_count directly
                        if args.use_top_seeds and seeds_by_count and count in seeds_by_count and seeds_by_count[count]:
                            # Choose a random seed from the top seeds for this count
                            seed = random.choice(seeds_by_count[count])
                        else:
                            # Use a sequential seed
                            seed = gen_count
                        
                        # Generate image
                        generator = torch.Generator(device=args.device).manual_seed(seed)
                        # Increment the generation counter before filename generation
                        gen_count += 1
                        
                        image = pipe(prompt, generator=generator).images[0]
                        
                        # Save image with filename format expected by gpt4o_request_evaluation.py
                        file_name = f"{plural}-{count}-{gen_count:04d}.jpg"
                        image_path = os.path.join(args.output_dir, file_name)
                        image.save(image_path)
                        
                        # Track metadata
                        metadata["prompts"].append(prompt)
                        metadata["objects"].append(plural)
                        metadata["counts"].append(count)
                        metadata["seeds"].append(seed)
                        metadata["settings"].append(setting)
                        metadata["filenames"].append(file_name)
                        
                        # Print information about the generated image
                        if args.num_images <= 10:  # Only print for smaller batches to avoid flooding console
                            print(f"{seed} | {prompt} | {file_name}")
                        
                        pbar.update(1)
    
    # Save metadata
    metadata_file = os.path.join(args.output_dir, "generation_metadata.pkl")
    with open(metadata_file, 'wb') as f:
        pickle.dump(metadata, f)
    
    print(f"Image generation complete! Generated {gen_count} images.")
    print(f"Metadata saved to {metadata_file}")
    
    print("\nNext steps:")
    print(f"1. Run evaluation with: python python_scripts/gpt4o_request_evaluation.py --input_dir \"{args.output_dir}\"")
    print(f"2. Then analyze results with: python python_scripts/final_evaluation.py --result_file \"{args.output_dir}/evaluation_results.pkl\"")


if __name__ == "__main__":
    main()
            
    